<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>llm_explainer_config.yaml - Security Extractor Pipeline</title>
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Arial, sans-serif; background:#0d1117; color:#c9d1d9; margin:0; }
  .header { padding:20px 32px; border-bottom:1px solid #30363d; background:#161b22; display:flex; justify-content:space-between; align-items:center; }
  h1 { margin:0; font-size:1.2rem; color:#e6edf3; }
  .back { color:#58a6ff; text-decoration:none; font-size:0.9rem; }
  .meta { padding:10px 32px; border-bottom:1px solid #30363d; color:#8b949e; font-size:0.85rem; }
  .wrap { padding:20px 32px; }
  pre { background:#161b22; border:1px solid #30363d; border-radius:8px; padding:16px; overflow:auto; font-family: ui-monospace, SFMono-Regular, Menlo, monospace; font-size:0.8rem; line-height:1.45; }
  .truncation-notice { margin-top:14px; color:#f0ad4e; border:1px solid #f0ad4e55; background:#1c1f26; border-radius:6px; padding:10px; text-align:center; font-size:0.84rem; }
</style>
</head>
<body>
  <div class="header">
    <h1>llm_explainer_config.yaml</h1>
    <a class="back" href="../pipeline_overview.html">&larr; Back to Overview</a>
  </div>
  <div class="meta">Total Lines: 45 | Category: Config File</div>
  <div class="wrap">
    <pre><code>llm_explainer:
  # Enable/disable LLM stage
  enabled: true

  # Prompt + selection
  top_n: 5
  prompt_template: &quot;config/llm_prompt_template.txt&quot;
  # Optional alternative to `prompt_template`:
  # prompt_template_text: |
  #   You are a strict JSON security explainer...

  # Generation controls
  timeout_seconds: 30
  max_output_tokens: 1800
  temperature: 0.2

  # Model routing
  model: &quot;openrouter/aurora-alpha&quot;
  max_model_attempts: 4
  allow_paid_fallback: true
  discover_free_models: false
  max_discovered_models: 6

  # Fallbacks
  paid_fallback_models:
    - &quot;openrouter/aurora-alpha&quot;
    - &quot;openrouter/auto&quot;

  fallback_models:
    - &quot;openrouter/auto&quot;
    - &quot;nousresearch/hermes-3-llama-3.1-405b:free&quot;
    - &quot;deepseek/deepseek-r1-0528:free&quot;
    - &quot;qwen/qwen3-coder:free&quot;
    - &quot;mistralai/mistral-small-3.1-24b-instruct:free&quot;

  free_fallback_models:
    - &quot;meta-llama/llama-3.3-70b-instruct:free&quot;
    - &quot;deepseek/deepseek-r1-0528:free&quot;
    - &quot;qwen/qwen3-coder:free&quot;
    - &quot;mistralai/mistral-small-3.1-24b-instruct:free&quot;

  # OpenRouter endpoint settings
  base_url: &quot;https://openrouter.ai/api/v1&quot;
  http_referer: &quot;http://localhost:5000&quot;
  app_title: &quot;SecurityExtractorPipeline&quot;</code></pre>
    
  </div>
</body>
</html>
